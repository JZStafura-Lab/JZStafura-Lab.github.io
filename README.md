# JAB Lab

**Cognitive Psychology, Neuroscience & Data Science**

This repository serves as both the source for the JAB Lab website and a hub for research code, tools, and documentation.

## About

JAB Lab uses modern technology to amplify the creation of research tools and the execution of small scale research. We use a learning-while-doing approach that insures content knowledge development through systematic curation and synthesis, as well as flexibility in execution. Hopefully, we also help some people.

JAB Lab investigates human cognition through experimental methods, ecological assessment, and computational analytics. Research focuses on understanding socio- cognitive processes in naturalistic contexts, including with AI. 

**Principal Investigator:** Joseph Zachary (JZ) Stafura, PhD

- [Google Scholar](https://scholar.google.com/citations?user=F6LcYIoAAAAJ&hl=en)
- [LinkedIn](https://www.linkedin.com/in/jzstafura)

## Current Projects

### Violence Research

Phase 1 is a website that explores  cognitive, social, and ecological factors underlying interpersonal violence, with focus on prediction, prevention, and intervention strategies.

Phase 2 (planned) model cards are created for each source collected in Phase 1, containing features from the articles, such as theoretical hypotheses, empirical findings, sample characteristics. The model card will drive an end-user filtered search for real world events through such sources as X, News RSS Feeds, and Real-Time databases such as ACLED. 

### Hallucitations Study

Examining the domain and expertise factorz underlying submitted and published texts containing AI hallucinations (e.g., "Hallucitations"). Currently conducting a pilot study with resource assitance from GPTZero.

### Evaluation Methods

Exploratory look into the frameworks and methods in Educational Evaluation 
and AI Evaluation. Where do best practices exist? Where does Evaluation in the domains differ in terms of validity, replicablity, and overall accessibility to end users. What can micro-sociology tell us about small scale evaluations of larger systems?

## Repository Structure

```
JZStafura-Lab.github.io/
├── README.md                     # Main repository documentation
├── LICENSE                       # MIT License
├── .gitignore                    # Python + R
├── _quarto.yml                   # Quarto site configuration
├── index.qmd                     # Homepage
├── projects.qmd                  # Projects overview
├── publications.qmd              # Publications list
├── code.qmd                      # Code/tools showcase
├── projects/                     # Project-specific content
│   ├── violence/
│   │   ├── README.md
│   │   ├── analysis/
│   │   ├── preprocessing/
│   │   └── visualization/
│   ├── hallucinations/
│   │   ├── README.md
│   │   ├── assessment/
│   │   ├── analysis/
│   │   └── visualization/
│   └── evaluation/
│       ├── README.md
│       ├── eval_tools_ed/
│       ├── eval_tools_ai/
│       ├── modeling/
│       └── visualization/
├── code/                         # Shared/reusable code
│   ├── python/
│   └── r/
├── data/
│   └── examples/                 # Small example datasets only
├── docs/                         # Quarto output (GitHub Pages)
└── assets/                       # Images, CSS, logos
    ├── jab_lab_logo.png
    └── css/
```

## Website

Visit the lab website: <https://jzstafura-lab.github.io>

Built with [Quarto](https://quarto.org) for reproducible research communication.

## Technologies

- **Languages:** R, Python, SQL
- **Statistical Methods:** GLM tradition, mixed models, psychometrics
- **Tools:** Quarto, RStudio, Jupyter, Git

## License

This project is licensed under the MIT License - see the <LICENSE> file for details.

## Contact

For research inquiries or collaboration opportunities, connect via [LinkedIn](https://www.linkedin.com/in/jzstafura).

-----

*Under active development*
